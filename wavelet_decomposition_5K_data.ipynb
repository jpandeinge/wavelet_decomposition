{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f44032-bf66-47de-a856-2c54a4c2d85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import glob\n",
    "import pywt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import ipywidgets as widgets\n",
    "# from IPython.display import display\n",
    "\n",
    "# %matplotlib widget\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fc427a-85d8-4f4c-978e-9835a5f5fe98",
   "metadata": {},
   "source": [
    "### Concatenate all the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c7def6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path to all files\n",
    "path = '../spectra/simulated_data/'\n",
    "files = sorted(glob.glob(path + 'model_parameters_data*.txt'), key=lambda x: int(re.search(r'\\d+', x).group()))\n",
    "# write_data = open('model_parameters_data_all.txt', 'w')\n",
    "# write_params  = open('model_parameters_all.txt', 'w')\n",
    "\n",
    "# # start timer\n",
    "# start_timer = time.time()\n",
    "# # read in all files\n",
    "# for file in files:\n",
    "#     with open(file, 'r') as f:\n",
    "#         # skip the first 10 lines in each file\n",
    "#         for i in range(10):\n",
    "#             f.readline()\n",
    "#             # read in the data from each file\n",
    "#         data = f.readlines()\n",
    "#         # get the length of the data in each file\n",
    "#         length = len(data)\n",
    "#         # write the data to the output file in the same order as the files\n",
    "#         for i in range(length):\n",
    "#             write_data.write(data[i])\n",
    "            \n",
    "# # close the files\n",
    "# write_data.close()\n",
    "# # # check how much time it took\n",
    "# print(time.time() - start_timer)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5886348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_timer = time.time()\n",
    "# # get the params data\n",
    "# df_param = pd.DataFrame()\n",
    "# for file in files:\n",
    "#     # get the parameters used\n",
    "#     df_param = df_param.append(pd.read_csv(file, skiprows=1, nrows=6, header=None, sep=' ', names=['A', 'B', 'C', 'D']))\n",
    "#     # save the dataframe to a csv file\n",
    "#     df_param.to_csv('model_parameters_data.csv', index=False)\n",
    "    \n",
    "# print(time.time() - start_timer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268cf9e9-4d06-4471-be10-6978f775226d",
   "metadata": {},
   "source": [
    "#### Load the files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25f7867",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "df_data = pd.read_csv('model_parameters_data_all.txt', sep=' ', header=None) # all data dataframe\n",
    "print(time.time() - start_time)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049a8be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706fc484-7eb5-4fb4-bf66-23d025f52ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_param = pd.read_csv('model_parameters_data.csv')\n",
    "df_param.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a4c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the second and fourth column\n",
    "df_param.drop(['B', 'D'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379d20bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data to the right dataframe\n",
    "df_param = df_param.assign(g = df_param.groupby('A').cumcount()).pivot(index='g', columns='A', values='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17258a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_param.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d5628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_param.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce7ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Frequency', 'Intensity']\n",
    "df_data.columns = columns\n",
    "df_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e020db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0687b22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_sig = np.array(np.array_split(df_data['Frequency'], len(files)))\n",
    "signal = np.array(np.array_split(df_data['Intensity'], len(files)))\n",
    "\n",
    "# plot the signal in one plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.plot(freq_sig[0],  signal[0], color='r', label='Spectrum 1')\n",
    "plt.plot(freq_sig[1], signal[1], color='g', label='Spectrum 2')\n",
    "plt.plot(freq_sig[2], signal[2], color='b', label='Spectrum 3')\n",
    "plt.plot(freq_sig[3], signal[3], color='y', label='Spectrum 4')\n",
    "plt.plot(freq_sig[4], signal[4], color='k', label='Spectrum 5')\n",
    "plt.xlabel(\"Frequency (GHz)\")\n",
    "plt.ylabel(\"Intensity (K)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd31b1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data in separate plots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15, 6))\n",
    "sns.set_style(\"whitegrid\")\n",
    "for i, ax in enumerate(axes.ravel(), start=1):\n",
    "    ax.plot(freq_sig[i-1], signal[i-1], label='Spectrum {}'.format(i))\n",
    "    ax.set_xlabel(\"Frequency (GHz)\", fontdict={'fontsize': 14})\n",
    "    ax.set_ylabel(\"Intensity (K)\", fontdict={'fontsize': 14})\n",
    "    ax.set_title(\"Spectrum {}\".format(i))\n",
    "    \n",
    "# plt.savefig('../spectra/simulated_data/spectrum_plots.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2c85d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pywt.wavelist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8bee59",
   "metadata": {},
   "source": [
    "### Feature Extraction - Wavelet Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29934f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a  feature vector array for each spectrum \n",
    "feature_vector = np.zeros((len(signal), int(df_data.shape[0]/len(files))))\n",
    "detail_coeffs = np.zeros((len(signal), 558))\n",
    "approx_coeffs = np.zeros((len(signal), 558))\n",
    "level = 6\n",
    "wname = 'db35'\n",
    "def decompose_signal_dwt(_signal, wavelet=wname, mode='per', level=level):\n",
    "    \"\"\"\n",
    "    Performs wavelet denoising on the given signal.\n",
    "    \"\"\"\n",
    "    # loop throuh all the spectra \n",
    "    for spectra_index in range(len(_signal)):\n",
    "        # max_level = pywt.dwt_max_level(len(_signal[spectra_index]), wavelet)\n",
    "        coeffs = pywt.wavedec(_signal[spectra_index], wavelet=wavelet, mode=mode, level=level)\n",
    "        coeff_arr, coeff_slices = pywt.coeffs_to_array(coeffs)\n",
    "        detail_coeffs[spectra_index, :] = coeff_arr[coeff_slices[1]['d']] # 4th level detail coeffs \n",
    "        # get the approximation coeffs\n",
    "        approx_coeffs[spectra_index, :] = coeffs[0] # 4th level approximation coeffs\n",
    "        \n",
    "        reconstructed_signal = pywt.waverec(coeffs, wavelet=wavelet, mode=mode)\n",
    "        feature_vector[spectra_index, :] = coeff_arr[:int(df_data.shape[0]/len(files))]\n",
    "        # add the coeff_arr to the dataframe for each spectra\n",
    "        # df_data['fv_dwt_{}'.format(wavelet)] = pd.Series(feature_vector.reshape(1, -1)[0], index=df_data.index) #TODO: find a way to optimize (or comment it out)\n",
    "        \n",
    "    return coeff_arr, coeff_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc1841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc5f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_timer = time.time()\n",
    "coeff_arr, coeff_slices = decompose_signal_dwt(signal)\n",
    "print(time.time() - start_timer)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7687132",
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_coeffs.shape\n",
    "detail_coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eb6be3",
   "metadata": {},
   "source": [
    "## Wavelet Decomposition Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b325988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decomposed_dwt_detail_coeffs_plots(_signal, wavelet=wname, level=level):\n",
    "    \"\"\"\n",
    "    Plots of the detail coeffs of the signal.\n",
    "    \"\"\"\n",
    "    # plot the reconstructed signal and the original signal in one plot\n",
    "    for spectra_index in range(len(_signal)):                     \n",
    "        # compute the maximum useful level of decomposition for each wavelet                        \n",
    "        # max_level = pywt.dwt_max_level(len(_signal[spectra_index]), wavelet)\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=level, dpi=400, sharey='none', sharex='all', figsize=(18, 5))\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        for i, ax in enumerate(axes.ravel(), start=1):\n",
    "            ax.plot(coeff_arr[coeff_slices[i]['d']], label='Level {}'.format(i))\n",
    "            ax.set_xlabel(\"Frequency (GHz)\", fontdict={'fontsize': 14})\n",
    "            ax.set_ylabel(\"Intensity (K)\", fontdict={'fontsize': 14})\n",
    "            ax.set_title(\"Spectrum {} detail coeffiecients at level {} for {} \".format(spectra_index+1, i, wavelet)) \n",
    "            \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a099b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# decomposed_dwt_detail_coeffs_plots(signal) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d9feea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find a way to plot the detail coefficients of the signal\n",
    "def decomposed_dwt_approx_coeffs_plots(_signal, wavelet=wname, level=level):\n",
    "    \n",
    "    for spectra_index in range(len(_signal)):\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=level, figsize=(10, 6))\n",
    "        sns.set_style(\"whitegrid\")\n",
    "        for i, ax in enumerate(axes.ravel(), start=1):\n",
    "            ax.plot(coeff_arr[coeff_slices[1]['d']])\n",
    "            ax.set_title(\"Spectrum {} approximation coeffiecients at level {} for {} \".format(spectra_index+1, i,  wavelet))\n",
    "            \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcba1ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# decomposed_dwt_approx_coeffs_plots(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09f34ae",
   "metadata": {},
   "source": [
    "### Get Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c6c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fv = np.zeros((len(signal), int(df.shape[0]/len(files))))\n",
    "# for spectra_index in range(len(signal)):\n",
    "#     # get the level 3 detail coefficients\n",
    "#     detail_coeffs = coeff_arr[coeff_slices[3]['d']]\n",
    "\n",
    "# fv  = detail_coeffs\n",
    "# labels =dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22b39a-d1a3-49ef-ad34-967617b3a6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(signal)\n",
    "\n",
    "approx_coeffs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7ca099-07fe-43c7-8f51-dffaea47e77b",
   "metadata": {},
   "source": [
    " #### Have a glimpse look at any of the signal and its generated detail and approximation coefficients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb5cc9-a745-445e-b09d-c4721e90663f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# for spectra_index in range(len(signal)):                     \n",
    "#         # compute the maximum useful level of decomposition for each wavelet                        \n",
    "#         # max_level = pywt.dwt_max_level(len(_signal[spectra_index]), wavelet)\n",
    "#         fig, axes = plt.subplots(nrows=1, ncols=10, sharey='none', sharex='all', figsize=(20, 7))\n",
    "#         sns.set_style(\"whitegrid\")\n",
    "#         for i, ax in enumerate(axes.ravel(), start=1):\n",
    "#             ax.plot(signal[spectra_index], label='Spectrum {}'.format(spectra_index))\n",
    "#             # ax.set_xlabel(\"Frequency (GHz)\", fontdict={'fontsize': 14})\n",
    "#             # ax.set_ylabel(\"Intensity (K)\", fontdict={'fontsize': 14})\n",
    "#             # ax.set_title(\"Spectrum {} detail coeffiecients at level {} for {} \".format(spectra_index+1, i, wavelet)) \n",
    "\n",
    "#     # ax[0,1].plot(signal[spectra_index], label='original')\n",
    "#     # ax[1,1].plot(approx_coeffs[spectra_index], label='spectrum {} approx coeff'.format(spectra_index+1))\n",
    "#     # ax[2,1].plot(detail_coeffs[spectra_index], label='spectrum {} detail coeff'.format(spectra_index+1))\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40ed4c8-22a4-4b54-96ad-ea515e68bad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "plt.plot(signal[243], label='original - 243')\n",
    "plt.legend()\n",
    "plt.savefig(\"5K_data/original.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fbd9db-c3ac-43d8-a85c-9af129f8c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "plt.plot(approx_coeffs[243], label='approx coeff - 243')\n",
    "plt.legend()\n",
    "plt.savefig(\"5K_data/approx_level6.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0298f81-1254-4b51-b1fd-ed2c087b3364",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,7))\n",
    "plt.plot(detail_coeffs[243], label='detail - 243')\n",
    "plt.legend()\n",
    "plt.savefig(\"5K_data/detail_level6.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b1086",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = detail_coeffs\n",
    "labels_ = df_param\n",
    "\n",
    "print('feature_shape: ', features.shape, 'labels_shape: ', labels_.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9439a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the tcmb column\n",
    "labels_.drop(columns=['tcmb'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9489549",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a05446",
   "metadata": {},
   "source": [
    "#### save the true params to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198312d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the last 1500 data of the parameters from labels \n",
    "df_param = df_param.iloc[-1500:, :]\n",
    "# save the vals to a csv file\n",
    "df_param.to_csv(\"5K_data/true_param_vals.csv\")\n",
    "df_param.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbab992-9582-4aeb-9867-a1b35e7a8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c460032-3229-4423-878b-d42828cc935d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(approx_coeffs)\n",
    "# df = pd.concat([approx_coeffs, labels_], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d265ac-f2df-424b-ac64-432c32b1b9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe257cd-99a4-40d5-a7f0-cbc7b946da98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802d06c9-730a-4581-a78c-7029034dc55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the ntot column to log values \n",
    "labels_['ntot'] = np.log(labels_['ntot'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fee9873-32c5-4ffd-ba2e-4015987ce791",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e34a0-b478-43df-b31c-4ce8bf181922",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, labels_], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d6c258-04ca-492b-8f67-9325cf4fa50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48d6e6-42dc-464b-9d2b-287ea9f465f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :558]\n",
    "y = df.iloc[:, -5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a83dd2",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b85770-ff82-47ff-87dc-a075a2c5689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2d92b3-cffa-4a4f-9752-9851a7b3e08d",
   "metadata": {},
   "source": [
    "#### split the data into the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db557e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.3,\n",
    "    shuffle=False,\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "print('X_train shape: ',  X_train.shape, '\\n',\n",
    "    'y_train shape: ', y_train.shape, '\\n',\n",
    "    'X_test shape: ', X_test.shape, '\\n',\n",
    "    'y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef77eda",
   "metadata": {},
   "source": [
    "## 1. Multioutput Regressor - RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c29340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "# regr_multirf = MultiOutputRegressor(\n",
    "#     RandomForestRegressor(\n",
    "#         max_depth=50\n",
    "#         ))\n",
    "\n",
    "# tuned model to use instantly\n",
    "regr_multirf = MultiOutputRegressor(\n",
    "    estimator=RandomForestRegressor(\n",
    "        bootstrap='False',\n",
    "        max_depth=90,\n",
    "        max_features='log2',\n",
    "        max_samples=0.8999999999999999,\n",
    "        n_estimators=700,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "))\n",
    "\n",
    "\n",
    "# pipe = make_pipeline(StandardScaler(), regr_multirf)\n",
    "# pipe.fit(X_train, y_train)  # apply scaling on training data\n",
    "\n",
    "\n",
    "# pipe.score(X_test, y_test)  # apply scaling on testing data, without leaking training data.\n",
    "\n",
    "# multioutput regressor\n",
    "regr_multirf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b363f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  predict on the new test data\n",
    "y_multirf_pred = regr_multirf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f83363c-bb27-48aa-971e-72af8da3f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_multirf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec40482-3bfc-4087-8f74-d641df4b8714",
   "metadata": {},
   "source": [
    "### save the predicted parameters to a csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41145fe-4a18-4588-a25c-1eed19b914f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df_rf = pd.DataFrame(y_multirf_pred, columns=['fwhm_rf_pred', 'ntot_rf_pred', 'size_rf_pred', 'tex_rf_pred', 'vlsr_rf_pred'])\n",
    "param_df_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5467b64f-0622-4eee-9ed7-1df7d54057bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert back the log to linear values \n",
    "param_df_rf['ntot_rf_pred'] = np.exp(param_df_rf['ntot_rf_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affcbf50-40bd-41c4-972f-7b9474c94abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df_rf.to_csv('5K_data/predicted_parameters_rf.csv')\n",
    "param_df_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cfee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_para = pd.read_csv('5K_data/predicted_parameters_rf.csv')\n",
    "true_para = pd.read_csv('5K_data/true_param_vals.csv')\n",
    "\n",
    "# add the predicted value to the true value dataframe as new columns separated by an empty column \n",
    "true_para = pd.concat([true_para,  pd.DataFrame(np.zeros(len(true_para))), param_df_rf], axis=1)\n",
    "true_para.to_csv('5K_data/true_param_vals_with_predicted_rf.csv')\n",
    "true_para.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e29dfa3-52c4-4268-a4bd-4d5e60bec3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('true val: {}'.format(y_test.iloc[:, 0]), 'pred_value: {}'.format( y_multirf_pred[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc4cd38-ef5c-4d93-8a8d-51f956cf40b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('true val: {}'.format(y_test.iloc[:, 1]), 'pred_value: {}'.format( y_multirf_pred[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa4592-58d6-4cdc-bc62-50ec28ca2ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('true val: {}'.format(y_test.iloc[:, 2]), 'pred_value: {}'.format( y_multirf_pred[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b9e4d-e385-4a2e-99ec-f5de5dc965f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('true val: {}'.format(y_test.iloc[:, 3]), 'pred_value: {}'.format( y_multirf_pred[:,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b33f429-4da7-42b1-8ebc-d1a1111df9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('true val: {}'.format(y_test.iloc[:, 4]), 'pred_value: {}'.format( y_multirf_pred[:,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403d8bcc",
   "metadata": {},
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58b8866",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionMetrics:\n",
    "    def __init__(self):\n",
    "        self.metrics = {\n",
    "            \"mae\": self._mean_absolute_error,\n",
    "            \"mse\": self._mean_squared_error,\n",
    "            \"rmse\": self._root_mean_squared_error,\n",
    "            \"mape\": self._mean_absolute_percentage_error,\n",
    "            \"r2\": self._r2_score,\n",
    "            \"msle\": self._mean_squared_log_error,\n",
    "            # \"rmsle\": self._root_mean_squared_logarithmic_error,\n",
    "        }\n",
    "\n",
    "    def get_metric(self, metric,  y_true, y_pred):\n",
    "        if metric not in self.metrics:\n",
    "            raise Exception(\"Metric not found\")\n",
    "        \n",
    "        if metric == \"mae\":\n",
    "            return self._mean_absolute_error(y_true, y_pred)\n",
    "        if metric == \"mse\":\n",
    "            return self._mean_squared_error(y_true, y_pred)\n",
    "        if metric == \"rmse\":\n",
    "            return self._root_mean_squared_error(y_true, y_pred)\n",
    "        if metric == \"mape\":\n",
    "            return self._mean_absolute_percentage_error(y_true, y_pred)\n",
    "        if metric == \"r2\":\n",
    "            return self._r2_score(y_true, y_pred)\n",
    "        if metric == \"msle\":\n",
    "            return self._mean_squared_log_error(y_true, y_pred)\n",
    "        # if metric == \"rmsle\":\n",
    "        #     return self._root_mean_squared_logarithmic_error(y_true, y_pred)\n",
    "        \n",
    "    @staticmethod\n",
    "    def _mean_absolute_error(y_true, y_pred):\n",
    "        return metrics.mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "    @staticmethod\n",
    "    def _mean_squared_error(y_true, y_pred):\n",
    "        return metrics.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    def _root_mean_squared_error(self, y_true, y_pred):\n",
    "        return np.sqrt(metrics.mean_squared_error(y_true, y_pred))\n",
    "\n",
    "    def _mean_absolute_percentage_error(self, y_true, y_pred):\n",
    "        return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    @staticmethod\n",
    "    def _r2_score(y_true, y_pred):\n",
    "        return metrics.r2_score(y_true, y_pred)\n",
    "    \n",
    "    def _mean_squared_log_error(self, y_true, y_pred):\n",
    "        return np.sqrt(metrics.mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    # TODO: investigate in the case where it gives an error\n",
    "    # def _root_mean_squared_logarithmic_error(self, y_true, y_pred):\n",
    "    #     return np.sqrt(np.mean(np.square(np.log(y_pred + 1) - np.log(y_true + 1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527a8e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the metricl for the multirf regressor\n",
    "metrics_multirf = RegressionMetrics()\n",
    "_metrics = ['mae', 'mse', 'rmse', 'mape', 'r2', 'msle']\n",
    "for metric in _metrics:\n",
    "    print(\"Multirf  {}: \".format(metric), metrics_multirf.get_metric(metric, y_test, y_multirf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c910cb85-f9f9-4255-acf5-726d34cac4ad",
   "metadata": {},
   "source": [
    "### Metrics on individual predicted parameters - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5590d5c-9407-4e0a-ac96-b07a1833c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"fwhm MSE:%.4f\" % metrics.mean_squared_error(y_test.iloc[:,0], y_multirf_pred[:,0]))\n",
    "print(\"ntot MSE:%.4f\" % metrics.mean_squared_error(y_test.iloc[:,1], y_multirf_pred[:,1]))\n",
    "print(\"size MSE:%.4f\" % metrics.mean_squared_error(y_test.iloc[:,2], y_multirf_pred[:,2]))\n",
    "print(\"tex MSE:%.4f\" % metrics.mean_squared_error(y_test.iloc[:,3], y_multirf_pred[:,3]))\n",
    "print(\"vlsr MSE:%.4f\" % metrics.mean_squared_error(y_test.iloc[:,4], y_multirf_pred[:,4]))\n",
    "\n",
    "print('\\n')\n",
    "print(\"fwhm MAE:%.4f\" % metrics.mean_absolute_error(y_test.iloc[:,0], y_multirf_pred[:,0]))\n",
    "print(\"ntot MAE:%.4f\" % metrics.mean_absolute_error(y_test.iloc[:,1], y_multirf_pred[:,1]))\n",
    "print(\"size MAE:%.4f\" % metrics.mean_absolute_error(y_test.iloc[:,2], y_multirf_pred[:,2]))\n",
    "print(\"tex MAE:%.4f\" % metrics.mean_absolute_error(y_test.iloc[:,3], y_multirf_pred[:,3]))\n",
    "print(\"vlsr MAE:%.4f\" % metrics.mean_absolute_error(y_test.iloc[:,4], y_multirf_pred[:,4]))\n",
    "\n",
    "print('\\n')\n",
    "print(\"fwhm MSLE:%.4f\" % metrics.mean_squared_log_error(y_test.iloc[:,0], y_multirf_pred[:,0]))\n",
    "print(\"ntot MSLE:%.4f\" % metrics.mean_squared_log_error(y_test.iloc[:,1], y_multirf_pred[:,1]))\n",
    "print(\"size MSLE:%.4f\" % metrics.mean_squared_log_error(y_test.iloc[:,2], y_multirf_pred[:,2]))\n",
    "print(\"tex MSLE:%.4f\" % metrics.mean_squared_log_error(y_test.iloc[:,3], y_multirf_pred[:,3]))\n",
    "# print(\"tex MSLE:%.4f\" % metrics.mean_squared_log_error(y_test.iloc[:,4], y_multirf_pred[:,4])) # TODO: normalize the values to have only +v values in the test-train set\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "# print(\"fwhm MAPE:%.4f\" % np.mean(np.abs((y_test.iloc[:,0] - y_multirf_pred[:,0]) / y_test.iloc[:,0])) * 100)\n",
    "# print(\"ntot MAPE:%.4f\" % np.mean(np.abs((y_test.iloc[:,1] - y_multirf_pred[:,1]) / y_test.iloc[:,1])) * 100)\n",
    "# print(\"size MAPE:%.4f\" %np.mean(np.abs((y_test.iloc[:,2] - y_multirf_pred[:,2]) / y_test.iloc[:,2])) * 100)\n",
    "# print(\"tex MAPE:%.4f\" % np.mean(np.abs((y_test.iloc[:,3] - y_multirf_pred[:,3]) / y_test.iloc[:,3])) * 100)\n",
    "# print(\"vlsr MAPE:%.4f\" % np.mean(np.abs((y_test.iloc[:,4] - y_multirf_pred[:,4]) / y_test.iloc[:,4])) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334270f6-907e-4c48-9cf3-c84613fed75a",
   "metadata": {},
   "source": [
    "## Predicted vs True values plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d796ce-e564-4975-ace1-5a95706725b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(45,35), dpi=150)\n",
    "plt.setp(ax.get_xticklabels(), fontsize=14)\n",
    "sns.set_theme(font_scale=2) \n",
    "axes[2,1].set_visible(False)\n",
    "axes[2,0].set_position([0.30, 0.1,0.40,0.25])\n",
    "\n",
    "g1 = sns.regplot(x=y_test.iloc[:,0], y=y_multirf_pred[:,0], color='blue', ax=axes[0,0]) # fwhm\n",
    "g2 = sns.regplot(x=y_test.iloc[:,1], y=y_multirf_pred[:,1], color='blue', ax=axes[0,1]) # column density\n",
    "g3 = sns.regplot(x=y_test.iloc[:,2], y=y_multirf_pred[:,2], color='blue', ax=axes[1,0]) # size\n",
    "g4 = sns.regplot(x=y_test.iloc[:,3], y=y_multirf_pred[:,3], color='blue', ax=axes[1,1]) # tex\n",
    "g5 = sns.regplot(x=y_test.iloc[:,4], y=y_multirf_pred[:,4], color='blue', ax=axes[2,0]) # vlsr\n",
    "\n",
    "g1.set(title='FWHM', ylabel=\"predicted values\", xlabel=\"true values\")\n",
    "g2.set(title='Column density', ylabel=\"predicted values\", xlabel=\"true values\", xscale='log', yscale='log')\n",
    "g3.set(title='Size', ylabel=\"predicted values\", xlabel=\"true values\")\n",
    "g4.set(title='Tex', ylabel=\"predicted values\", xlabel=\"true values\")\n",
    "g5.set(title='Vlsr', ylabel=\"predicted values\", xlabel=\"true values\")\n",
    "\n",
    "plt.savefig(\"5K_data/pred_true_5K_RF.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dd2229-1995-48f7-9327-f0696de5d3ff",
   "metadata": {},
   "source": [
    "### 3D plots -  Columnn density, Excitation temperature and Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227420a0-0972-45f5-a697-bc9a13bfd6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_param_rf = pd.DataFrame(y_multirf_pred, columns=['fwhm', 'ntot', 'size', 'tex', 'vlsr'])\n",
    "pred_param_rf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bd228e",
   "metadata": {},
   "source": [
    "### Residuals 3D plot -  Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aec75ea-146f-4af3-9915-ac73e008f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(26, 11), dpi=120)\n",
    "plt.setp(ax.get_xticklabels(), fontsize=12)\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "\n",
    "markers = ['D', 's', '.']\n",
    "labels = ['ntot', 'tex', 'size']\n",
    "colors = ['black', 'red', 'blue']\n",
    "\n",
    "residuals_rf = (y_test - y_multirf_pred)\n",
    "# residuals\n",
    "x1 = residuals_rf['ntot']\n",
    "y1 = residuals_rf['tex']\n",
    "z1 = residuals_rf['size']\n",
    "\n",
    "for i in range(len(markers)):\n",
    "    ax1.scatter3D(x1, y1, z1, marker=markers[i], c=colors[i], label=labels[i])\n",
    "\n",
    "ax1.set_title('ntot-tex-size distribution - Residuals')\n",
    "ax1.set_xlabel('Column Density')\n",
    "ax1.set_ylabel('Excitation Temperature')\n",
    "ax1.set_zlabel('Size')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a8a4ee-bc7b-40ec-a0e6-4c841d6c0db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(45,35), dpi=250)\n",
    "plt.setp(ax.get_xticklabels(), fontsize=14)\n",
    "sns.set_theme(font_scale=2) \n",
    "axes[2,1].set_visible(False)\n",
    "axes[2,0].set_position([0.30, 0.1,0.40,0.25])\n",
    "\n",
    "# plot the redisual distribution using seaborn\n",
    "g1 = sns.residplot(x=y_multirf_pred[:,0], y=residuals_rf['fwhm'], lowess=True, ax=axes[0,0]) # fwhm\n",
    "g2 = sns.residplot(x=y_multirf_pred[:,1], y=residuals_rf['ntot'], lowess=True, ax=axes[0,1]) # column density\n",
    "g3 = sns.residplot(x=y_multirf_pred[:,2], y=residuals_rf['size'], lowess=True, ax=axes[1,0]) # size\n",
    "g4 = sns.residplot(x=y_multirf_pred[:,3], y=residuals_rf['size'], lowess=True, ax=axes[1,1]) # tex\n",
    "g5 = sns.residplot(x=y_multirf_pred[:,4], y=residuals_rf['vlsr'], lowess=True, ax=axes[2,0]) # vlsr\n",
    "\n",
    "g1.set(title='FWHM', ylabel=\"residuals\", xlabel=\"predicted values\")\n",
    "g2.set(title='Column density', ylabel=\"residuals\", xlabel=\"predicted values\")\n",
    "g3.set(title='Size', ylabel=\"predicted values\", xlabel=\"predicted values\")\n",
    "g4.set(title='Tex', ylabel=\"residuals\", xlabel=\"predicted values\")\n",
    "g5.set(title='Vlsr', ylabel=\"residuals\", xlabel=\"predicted values\")\n",
    "\n",
    "plt.savefig(\"5K_data/residuals_RF_5K.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36006a47-7ff0-40f7-83ec-9286e938ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(35, 25), dpi=400)\n",
    "plt.setp(ax.get_xticklabels(), fontsize=14)\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "\n",
    "markers = ['D', 's', '.']\n",
    "labels = ['ntot', 'tex', 'size']\n",
    "colors = ['black', 'red', 'blue']\n",
    "\n",
    "x2 = y_test['ntot']\n",
    "y2 = y_test['tex']\n",
    "z2 = y_test['size']\n",
    "\n",
    "\n",
    "for i in range(len(markers)):\n",
    "    x1 = pred_param_rf['ntot']\n",
    "    y1 = pred_param_rf['tex']\n",
    "    z1 = pred_param_rf['size']\n",
    "    \n",
    "    ax1.scatter3D(x1, y1, z1, marker=markers[i], c=colors[i], label=labels[i])\n",
    "    ax2.scatter3D(x2, y2, z2, marker=markers[i], color=colors[i], label=labels[i])\n",
    "\n",
    "ax1.set_title('ntot-tex-size distribution - Predicted Values')\n",
    "ax1.set_xlabel('Column Density')\n",
    "ax1.set_ylabel('Excitation Temperature')\n",
    "ax1.set_zlabel('Size')\n",
    "\n",
    "\n",
    "ax2.set_title('ntot-tex-size distribution - True Values')\n",
    "ax2.set_xlabel('Column Density')\n",
    "ax2.set_ylabel('Excitation Temperature')\n",
    "ax2.set_zlabel('Size')\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.savefig(\"5K_data/scatter3D_pred_true_5K_RF.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bb00ff-e347-440a-aaa0-5cf1bf61c722",
   "metadata": {},
   "source": [
    "All the points are taking up the same position in a 3D space. Not sure if this is how its supposed to be. From my understanding, the Column density is dependent on Temperature, so they take the `x`, and `y` positions while size takes the `z` position.plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc78653",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b8823d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "multirf_model = MultiOutputRegressor(\n",
    "    RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        min_weight_fraction_leaf=0.0,\n",
    "        criterion=\"squared_error\",\n",
    "        bootstrap=True,\n",
    "        n_jobs=-1,\n",
    "        max_samples=None,\n",
    "))\n",
    "\n",
    "multrf_hyperparameters = dict(\n",
    "    estimator__n_estimators=np.arange(100, 1000, 100),\n",
    "    estimator__max_depth=np.arange(10, 150, 10),\n",
    "    estimator__min_samples_split=np.arange(2, 10, 2),\n",
    "    estimator__min_samples_leaf=np.arange(1, 5, 1),\n",
    "    # estimator__min_weight_fraction_leaf=np.arange(0, 0.5, 0.1),\n",
    "    # estimator__criterion=[\"squared_error\", \"absolute_error\"],\n",
    "    estimator__max_features=[\"auto\", \"sqrt\", \"log2\"],\n",
    "    # estimator__max_samples=np.arange(0.5, 1, 0.1),\n",
    "    estimator__bootstrap=[\"True\", \"False\"]\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2e1a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(\n",
    "    estimator=multirf_model,\n",
    "    param_distributions=multrf_hyperparameters,\n",
    "    n_iter=100,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    error_score=\"raise\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae006e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_rf_tuned_model = random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600000be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters: \", hyper_rf_tuned_model.best_params_)\n",
    "print(\"Best score: \", hyper_rf_tuned_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585c8841-6edc-4376-b46f-42643060a4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_rf_model = hyper_rf_tuned_model.best_estimator_\n",
    "y_multrf_tuned_tf = tuned_rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393b64ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: interpret the model evaluation metrics\n",
    "# eval = RegressionMetrics()\n",
    "# for metric in _metrics:\n",
    "#     print(metric, \":\", eval.get_metric(metric, y_test, y_multrf_tuned_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1bfafa",
   "metadata": {},
   "source": [
    "## 2. XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3740287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "multixgb_model = MultiOutputRegressor(\n",
    "    xgb.XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        max_leaves=10,\n",
    "        max_bin=10,\n",
    "        learning_rate=0.1,\n",
    "        n_jobs=-1,\n",
    "        gamma=0,\n",
    "        min_child_weight=1.0,\n",
    "        max_delta_step=0,\n",
    "        importance_type=\"gain\",\n",
    "        eval_metric=metrics.mean_squared_error\n",
    "    )\n",
    ")\n",
    "\n",
    "# xgb_hyperparameters = dict(\n",
    "#     estimator__n_estimators=np.arange(100, 1000, 100),\n",
    "#     estimator__max_depth=np.arange(10, 150, 10),\n",
    "#     estimator__max_leaves=np.arange(10, 150, 10),\n",
    "#     estimator__max_bin=np.arange(10, 150, 10),\n",
    "#     # estimator_growth_policy=0,\n",
    "#     estimator__learning_rate=np.arange(0.1, 1, 0.1),\n",
    "#     estimator__min_child_weight=np.arange(1.0, 5.0, 0.5),\n",
    "#     estimator__max_delta_step=np.arange(0, 10, 1),\n",
    "#     estimator__importance_type=[\"gain\", \"weight\", \"cover\", \"total_gain\", \"total_cover\"],\n",
    "#     estimator__eval_metric=[metrics.mean_absolute_error, metrics.mean_squared_error]\n",
    "# )\n",
    "\n",
    "# xgbr_rand_search = RandomizedSearchCV(\n",
    "#     estimator=multixgb_model,\n",
    "#     param_distributions=xgb_hyperparameters,\n",
    "#     n_iter=100,\n",
    "#     cv=3\n",
    "# )\n",
    "\n",
    "# xgb_hyperparameters_tuning = xgbr_rand_search.fit(X_train, y_train)\n",
    "# print('Best Parameters = {}'.format(xgb_hyperparameters_tuning.best_params_))\n",
    "\n",
    "# xgb_tuned_model = xgb_hyperparameters_tuning.best_estimator_\n",
    "\n",
    "multixgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c489fc-292e-4cdc-96f1-90239c930366",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_multixgb_pred = multixgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d85ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in _metrics:\n",
    "    print(metric, \":\", metrics_multirf.get_metric(metric, y_test, y_multixgb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341dfb89-5c74-4e02-8184-c8e975bbabd0",
   "metadata": {},
   "source": [
    "### Metrics on individual predicted parameters - XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ca1cd5-82de-4953-b477-39b355d01562",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"fwhm MSE:%.4f\" % metrics.mean_squared_error(y_test.iloc[:,0], y_multixgb_pred[:,0]))\n",
    "print(\"ntot MSE:%.4f\" % metrics.mean_squared_error(y_test.iloc[:,1], y_multixgb_pred[:,1]))\n",
    "print(\"size MSE:%.4f\" % metrics.mean_squared_error(y_test.iloc[:,2], y_multixgb_pred[:,2]))\n",
    "print(\"tex MSE:%.4f\" % metrics.mean_squared_error(y_test.iloc[:,3], y_multixgb_pred[:,3]))\n",
    "print(\"vlsr MSE:%.4f\" % metrics.mean_squared_error(y_test.iloc[:,4], y_multixgb_pred[:,4]))\n",
    "\n",
    "print('\\n')\n",
    "print(\"fwhm MSLE:%.4f\" % metrics.mean_squared_log_error(y_test.iloc[:,0], y_multixgb_pred[:,0]))\n",
    "print(\"ntot MSLE:%.4f\" % metrics.mean_squared_log_error(y_test.iloc[:,1], y_multixgb_pred[:,1]))\n",
    "print(\"size MSLE:%.4f\" % metrics.mean_squared_log_error(y_test.iloc[:,2], y_multixgb_pred[:,2]))\n",
    "# print(\"tex MSLE:%.4f\" % metrics.mean_squared_log_error(y_test.iloc[:,3], y_multixgb_pred[:,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6b596f-4348-4219-b9b6-3ba32c59af2a",
   "metadata": {},
   "source": [
    "### save the predicted parameters to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2e0fb6-beac-4a94-9385-610b48cf0318",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df_xgb = pd.DataFrame(y_multixgb_pred, columns=['fwhm_pred_xgb', 'ntot_pred_xgb', 'size_pred_xgb', 'tex_pred_xgb', 'vlsr_xgb_pred'])\n",
    "param_df_xgb['ntot_pred_xgb'] = np.exp(param_df_xgb['ntot_pred_xgb'])\n",
    "param_df_xgb.to_csv('5K_data/predicted_parameters_xgb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022728e2-783f-4e18-b20a-92ec24c03e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df_xgb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0a95e7-3e01-436d-80c0-5a289953c8fd",
   "metadata": {},
   "source": [
    "### Predicted vs True values - XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc63c6a1-1471-4069-990d-80e02d80db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cebcc58-a3ae-43f1-b2ff-0e0b03034889",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(45,35), dpi=150)\n",
    "plt.setp(ax.get_xticklabels(), fontsize=14)\n",
    "sns.set_theme(font_scale=2) \n",
    "axes[2,1].set_visible(False)\n",
    "axes[2,0].set_position([0.30, 0.1,0.40,0.25])\n",
    "\n",
    "g1 = sns.regplot(x=y_test.iloc[:, 0], y=y_multixgb_pred[:,0], color='blue', ax=axes[0,0]) # fwhm\n",
    "g2 = sns.regplot(x=y_test.iloc[:,1], y=y_multixgb_pred[:,1], color='blue', ax=axes[0,1]) # column density\n",
    "g3 = sns.regplot(x=y_test.iloc[:,2], y=y_multixgb_pred[:,2], color='blue', ax=axes[1,0]) # size\n",
    "g4 = sns.regplot(x=y_test.iloc[:,3], y=y_multixgb_pred[:,3], color='blue', ax=axes[1,1]) # tex\n",
    "g5 = sns.regplot(x=y_test.iloc[:,4], y=y_multixgb_pred[:,4], color='blue', ax=axes[2,0]) # vlsr\n",
    "\n",
    "g1.set(title='FWHM', ylabel=\"predicted values\", xlabel=\"true values\")\n",
    "g2.set(title='Column density', ylabel=\"predicted values\", xlabel=\"true values\", yscale=\"log\", xscale=\"log\")\n",
    "g3.set(title='Size', ylabel=\"predicted values\", xlabel=\"true values\")\n",
    "g4.set(title='Tex', ylabel=\"predicted values\", xlabel=\"true values\")\n",
    "g5.set(title='Vlsr', ylabel=\"predicted values\", xlabel=\"true values\")\n",
    "\n",
    "plt.savefig(\"5K_data/pred_true_5K_XGB.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261d52c6-a271-4739-a8b4-9da2bbf2e6e7",
   "metadata": {},
   "source": [
    "### 3D plots - Columnn density, Excitation temperature and Size - XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2870cf17-3d99-4164-89d6-6cebbdd62f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_param_xgb = pd.DataFrame(y_multixgb_pred, columns=['fwhm', 'ntot', 'size', 'tex', 'vlsr'])\n",
    "pred_param_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad2568-82dc-4e46-895e-f3b4188ecd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(35, 25), dpi=400)\n",
    "plt.setp(ax.get_xticklabels(), fontsize=14)\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "\n",
    "\n",
    "markers = ['D', 's', '.']\n",
    "labels = ['ntot', 'tex', 'size']\n",
    "colors = ['black', 'red', 'blue']\n",
    "\n",
    "\n",
    "x1 = pred_param_xgb['ntot']\n",
    "y1 = pred_param_xgb['tex']\n",
    "z1 = pred_param_xgb['size']\n",
    "    \n",
    "x2 = y_test['ntot']\n",
    "y2 = y_test['tex']\n",
    "z2 = y_test['size']\n",
    "\n",
    "\n",
    "for i in range(len(markers)):\n",
    "    ax1.scatter3D(x1, y1, z1, marker=markers[i], c=colors[i], label=labels[i])\n",
    "    ax2.scatter3D(x2, y2, z2, marker=markers[i], color=colors[i], label=labels[i])\n",
    "\n",
    "ax1.set_title('ntot-tex-size distribution - Predicted Values')\n",
    "ax1.set_xlabel('Column Density')\n",
    "ax1.set_ylabel('Excitation Temperature')\n",
    "ax1.set_zlabel('Size')\n",
    "\n",
    "\n",
    "ax2.set_title('ntot-tex-size distribution - True Values')\n",
    "ax2.set_xlabel('Column Density', )\n",
    "ax2.set_ylabel('Excitation Temperature')\n",
    "ax2.set_zlabel('Size')\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.savefig(\"5K_data/scatter3D_pred_true_5K_XGB.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06442a98-b2cd-4917-b8b1-7d86cabe4ed9",
   "metadata": {},
   "source": [
    "### Residuals 3D plot - XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22367f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 7), dpi=120)\n",
    "plt.setp(ax.get_xticklabels(), fontsize=14)\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "\n",
    "markers = ['D', 's', '.']\n",
    "labels = ['ntot', 'tex', 'size']\n",
    "colors = ['black', 'red', 'blue']\n",
    "\n",
    "residuals_xgb = (y_test - y_multixgb_pred)\n",
    "# residuals\n",
    "x1 = residuals_xgb['ntot']\n",
    "y1 = residuals_xgb['tex']\n",
    "z1 = residuals_xgb['size']\n",
    "\n",
    "for i in range(len(markers)):\n",
    "    ax1.scatter3D(x1, y1, z1, marker=markers[i], c=colors[i], label=labels[i])\n",
    "\n",
    "ax1.set_title('ntot-tex-size distribution - Residuals')\n",
    "ax1.set_xlabel('Column Density')\n",
    "ax1.set_ylabel('Excitation Temperature')\n",
    "ax1.set_zlabel('Size')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8558b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(45,35), dpi=250)\n",
    "plt.setp(ax.get_xticklabels(), fontsize=14)\n",
    "sns.set_theme(font_scale=2) \n",
    "axes[2,1].set_visible(False)\n",
    "axes[2,0].set_position([0.30, 0.1,0.40,0.25])\n",
    "\n",
    "# plot the redisual distribution using seaborn\n",
    "g1 = sns.residplot(x=y_multixgb_pred[:,0], y=residuals_xgb['fwhm'], lowess=True, ax=axes[0,0]) # fwhm\n",
    "g2 = sns.residplot(x=y_multixgb_pred[:,1], y=residuals_xgb['ntot'], lowess=True, ax=axes[0,1]) # column density\n",
    "g3 = sns.residplot(x=y_multixgb_pred[:,2], y=residuals_xgb['size'], lowess=True, ax=axes[1,0]) # size\n",
    "g4 = sns.residplot(x=y_multixgb_pred[:,3], y=residuals_xgb['size'], lowess=True, ax=axes[1,1]) # tex\n",
    "g5 = sns.residplot(x=y_multixgb_pred[:,4], y=residuals_xgb['vlsr'], lowess=True, ax=axes[2,0]) # vlsr\n",
    "\n",
    "g1.set(title='FWHM', ylabel=\"residuals\", xlabel=\"predicted values\")\n",
    "g2.set(title='Column density', ylabel=\"residuals\", xlabel=\"predicted values\")\n",
    "g3.set(title='Size', ylabel=\"predicted values\", xlabel=\"predicted values\")\n",
    "g4.set(title='Tex', ylabel=\"residuals\", xlabel=\"predicted values\")\n",
    "g5.set(title='Vlsr', ylabel=\"residuals\", xlabel=\"predicted values\")\n",
    "\n",
    "plt.savefig(\"5K_data/residuals_XGB_5K.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de28602",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor - Grid Search for Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085ec7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MultiOutputRegressor(\n",
    "#     GradientBoostingRegressor(\n",
    "#         loss='ls', \n",
    "#         learning_rate=0.1, \n",
    "#         n_estimators=100, \n",
    "#         subsample=1.0,\n",
    "#         criterion='friedman_mse', \n",
    "#         min_samples_split=2,\n",
    "#         min_samples_leaf=1,\n",
    "#         min_weight_fraction_leaf=0.0,\n",
    "#         max_depth=3,\n",
    "#         min_impurity_decrease=0.0,\n",
    "#         init=None, \n",
    "#         random_state=None,\n",
    "#         max_features=None,\n",
    "#         alpha=0.9, \n",
    "#         verbose=0, \n",
    "#         max_leaf_nodes=None, \n",
    "#         warm_start=False,\n",
    "#         validation_fraction=0.1, \n",
    "#         n_iter_no_change=None, \n",
    "#         tol=0.0001,\n",
    "#         ccp_alpha=0.0))\n",
    "\n",
    "# hyperparameters = dict(\n",
    "#     estimator__learning_rate=[0.0001, 0.05, 0.1, 0.2, 0.5, 0.9], \n",
    "#     estimator__loss=['ls', 'absolute_error', 'huber'],\n",
    "#     estimator__n_estimators=[10, 20, 50, 100, 200, 300, 500, 700, 1000],\n",
    "#     estimator__criterion=['friedman_mse', 'squared_error'], \n",
    "#     estimator__min_samples_split=np.arange(2, 12, 2),\n",
    "#     estimator__max_depth=[3, 5, 10, 15, 20, 30], \n",
    "#     estimator__min_samples_leaf=[1, 2, 3, 5, 8, 10],\n",
    "#     estimator__min_impurity_decrease=[0, 0.2, 0.4, 0.6, 0.8],\n",
    "#     estimator__max_leaf_nodes=[5, 10, 20, 30, 50, 100, 300])\n",
    "\n",
    "# randomized_search = RandomizedSearchCV(\n",
    "#     model, \n",
    "#     hyperparameters, \n",
    "#     random_state=0, \n",
    "#     n_iter=5, \n",
    "#     scoring=None,\n",
    "#     n_jobs=2, \n",
    "#     refit=True, \n",
    "#     cv=5, \n",
    "#     verbose=True,\n",
    "#     pre_dispatch='2*n_jobs', \n",
    "#     error_score='raise', \n",
    "#     return_train_score=True)\n",
    "\n",
    "# hyperparameters_tuning = randomized_search.fit(X_train, y_train)\n",
    "# print('Best Parameters = {}'.format(hyperparameters_tuning.best_params_))\n",
    "\n",
    "# tuned_model = hyperparameters_tuning.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5630d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tuned_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740f5df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use the metrics class to calculate the metrics from the tuned model\n",
    "# eval = RegressionMetrics()\n",
    "# for metric in [\"mae\", \"mse\", \"rmse\", \"mape\", \"r2\", \"msle\"]:\n",
    "#     print(metric, \":\", eval.get_metric(metric, y_test, tuned_model.predict(X_test)))\n",
    "# #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c705767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "701d4f28dcd0866722f5108a3a4cbcd08882d26398b6d44117e791d7b8102912"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
